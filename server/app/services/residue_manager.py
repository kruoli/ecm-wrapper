"""
Residue file manager service for decoupled two-stage ECM.

Handles:
- Parsing residue file metadata
- Storing/retrieving residue files
- Work assignment for stage 2
- Lifecycle management (claim, complete, expire)
"""

import logging
import hashlib
import re

import math
from pathlib import Path
from typing import Optional, Tuple, Dict, Any
from datetime import datetime, timedelta

from sqlalchemy.orm import Session
from sqlalchemy import and_, func

from ..models.residues import ECMResidue
from ..models.composites import Composite
from ..models.attempts import ECMAttempt
from ..config import get_settings
from .t_level_calculator import TLevelCalculator

logger = logging.getLogger(__name__)


class ResidueManager:
    """Manages ECM residue files for decoupled two-stage processing."""

    ALLOWED_EVAL_CHARS = "0123456789+-*/^()" # prevent abusing eval(…), DO NOT CHANGE!
    CHKCONST = 4294967291 # from GMP-ECM's CHKSUMMOD (ecm/ecm-ecm.h:170)
    EXPONENTATION_PATTERN = re.compile(r'(\d+)\*\*(\d+)')

    def __init__(self):
        """Initialize the residue manager."""
        settings = get_settings()
        self.storage_dir = Path(settings.residue_storage_path)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        self.t_level_calculator = TLevelCalculator()

    def parse_residue_file(self, file_content: bytes, b1_in: Optional[int]) -> Dict[str, Any]:
        """
        Parse metadata from a residue file.

        Args:
            file_content: Raw bytes of the residue file
            b1_in: B1 of a residue file that was created with Prime95/mprime

        Returns:
            Dict with keys: composite, b1, parametrization, curve_count

        Raises:
            ValueError: If file format is invalid or missing required fields
        """
        try:
            content = file_content.decode('utf-8')
        except UnicodeDecodeError as e:
            raise ValueError(f"Residue file is not valid UTF-8: {e}")

        raw_lines = content.strip().replace('\r', '').split('\n')
        lines = [line.strip() for line in raw_lines if line.strip() and not line.lstrip().startswith(('[', '#'))]
        if not lines:
            raise ValueError("Residue file is empty")

        # Parse first line to get metadata
        first_line = lines[0]

        # There are multiple valid stage 1 save file formats. The most important ones are:
        # - GMP-ECM's current save format (has a checksum) that can be used with CPU and CUDA GPU
        #  …and…
        # - Prime95/mprime's format, accepted by GMP-ECM as input (from version 22 onward)
        # While using CGBN is useful for small- and medium-sized numbers, Prime95/mprime's fast FFTs shine when larger
        # numbers are being processed and especially when AVX512 is available. Though one should note that
        # Prime95/mprime limits bases to 32-bit numbers and are best when the base is as small as possible and there are
        # no non-trivial cofactors known. (Cofactors do not slow things down, but also do not speed things up unlike
        # with CGBN when going down to a smaller kernel.) Another disadvantage of Prime95/mprime is that it does not
        # include B1.
        # To use this feature, GmpEcmHook=1 needs to be added to prime.txt; output can be found in results.txt, but may
        # have to be stripped of timestamps.

        line_elements = [el.strip() for el in first_line.split(';') if el.strip()]
        split_elements = [el.split('=', 1) for el in line_elements]
        available_keys = [parts[0] for parts in split_elements if len(parts) > 1]

        # Common parameters
        param_of_residue_index = available_keys.index("PARAM")
        param_of_residue = int(split_elements[param_of_residue_index][1])
        n_str_index = available_keys.index("N")
        n_str: str
        n_str = split_elements[n_str_index][1] # hexadecimal number with prefix OR decimal expression
        curve_count = sum(1 for line in lines if "SIGMA=" in line) # count curves (each line with SIGMA= is a curve)

        # Check if the data comes from Prime95/mprime
        if "QX" in available_keys: # special key for identification
            if b1_in is None:
                raise ValueError("B1 was not set despite processing a Prime95/mprime file")

            b1 = b1_in
            composite = int(n_str, 0) # "base 0" allows for a 0x prefix

        else: # GMP-ECM format
            if "CHECKSUM" not in available_keys:
                raise ValueError("An original GMP-ECM residue had no checksum")

            if n_str.isdecimal(): # pure decimal
                composite = int(n_str)

            elif n_str[:2].lower() == "0x" and n_str[2:].isdecimal(): # hexadecimal
                composite = int(n_str[2:], 16)

            elif not n_str.strip(self.ALLOWED_EVAL_CHARS): # only mathematical characters allowed
                python_expr: str
                python_expr = n_str.replace("^", "**").replace("/", "//")

                # only allow one exponentiation in expression (sufficient for OPN numbers)
                exponentiation_count = python_expr.count("**")
                if exponentiation_count > 1:
                    raise ValueError(f"Only one exponentation per expression allowed")

                elif exponentiation_count > 0:
                    match = self.EXPONENTATION_PATTERN.search(python_expr)
                    if not match:
                        ValueError(f"Exponentiations do not support brackets nor negative exponents")

                    # make sure the resulting number is reasonably small
                    base = int(match.group(1))
                    exponent = int(match.group(2))
                    if exponent * math.log10(base) > 100000:
                        raise ValueError(f"N too big")

                composite = int(eval(python_expr))

            else:
                raise ValueError(f"N has an unknown format: {n_str}")

            b1_index = available_keys.index("B1")
            b1 = int(split_elements[b1_index][1])

            # Check residues for validity
            for line in lines:
                line_elements = [el.strip() for el in line.split(';') if el.strip()]
                split_elements = [el.split('=', 1) for el in line_elements]
                available_keys = [parts[0] for parts in split_elements if len(parts) > 1]
                checksum_index = available_keys.index("CHECKSUM")
                checksum = int(split_elements[checksum_index][1])

                # Calculate checksum of line
                checksum_calc = b1
                sigma_index = available_keys.index("SIGMA")
                sigma = int(split_elements[sigma_index][1])
                # Note: differing from most checksum implementations, GMP-ECM always does a MOD operation first
                #       and a MUL operation second, which look like this:
                #       mpz_mul_ui(checksum_calc, checksum_calc, mpz_fdiv_ui(some_val, CHKCONST))
                checksum_calc *= sigma % self.CHKCONST
                checksum_calc *= composite % self.CHKCONST
                x_index = available_keys.index("X")
                x = int(split_elements[x_index][1], 0) # field X is always in hexadecimal format
                checksum_calc *= x % self.CHKCONST
                checksum_calc *= param_of_residue + 1 # does not need a MOD operation
                checksum_calc %= self.CHKCONST

                if checksum != checksum_calc:
                    raise ValueError("A line did not match its expected checksum")

        if not curve_count:
            raise ValueError("No curves found in residue file")

        return {
            'composite': str(composite),
            'b1': b1,
            'parametrization': param_of_residue,
            'curve_count': curve_count
        }

    def calculate_checksum(self, file_content: bytes) -> str:
        """Calculate SHA-256 checksum of file content."""
        return hashlib.sha256(file_content).hexdigest()

    def store_residue_file(
        self,
        db: Session,
        file_content: bytes,
        client_id: str,
        stage1_attempt_id: Optional[int] = None,
        b1: Optional[int] = None
    ) -> ECMResidue:
        """
        Store a residue file and create database record.

        Residues don't expire by time - they remain available until:
        - The composite is fully factored
        - A stage 2 worker completes processing them

        Args:
            db: Database session
            file_content: Raw residue file bytes
            client_id: ID of the uploading client
            stage1_attempt_id: Optional ID of the stage 1 attempt to link
            b1: B1 of a residue file that was created with Prime95/mprime

        Returns:
            ECMResidue database record

        Raises:
            ValueError: If file format is invalid or composite not found
        """
        # Parse metadata from file
        metadata = self.parse_residue_file(file_content, b1)
        composite_number = metadata['composite']

        # Look up composite in database
        composite = db.query(Composite).filter(
            Composite.current_composite == composite_number
        ).first()

        if not composite:
            # Try matching by number field as fallback
            composite = db.query(Composite).filter(
                Composite.number == composite_number
            ).first()

        if not composite:
            raise ValueError(f"Composite {composite_number[:50]}... not found in database")

        # Generate unique filename
        import uuid
        file_uuid = str(uuid.uuid4())
        composite_dir = self.storage_dir / str(composite.id)
        composite_dir.mkdir(parents=True, exist_ok=True)
        file_path = composite_dir / f"{file_uuid}.txt"

        # Calculate checksum
        checksum = self.calculate_checksum(file_content)

        # Check for duplicate by checksum
        existing = db.query(ECMResidue).filter(
            ECMResidue.checksum == checksum
        ).first()
        if existing:
            raise ValueError(f"Duplicate residue file (checksum matches residue ID {existing.id})")

        # Write file to storage
        file_path.write_bytes(file_content)
        logger.info(f"Stored residue file: {file_path} ({len(file_content)} bytes)")

        # Create database record
        # expires_at is None for available residues (no time-based expiration)
        # It will be set when claimed (claim timeout)
        residue = ECMResidue(
            composite_id=composite.id,
            client_id=client_id,
            stage1_attempt_id=stage1_attempt_id,
            b1=metadata['b1'],
            parametrization=metadata['parametrization'],
            curve_count=metadata['curve_count'],
            storage_path=str(file_path),
            file_size_bytes=len(file_content),
            checksum=checksum,
            status='available',
            expires_at=None
        )

        db.add(residue)
        db.flush()  # Get the ID

        logger.info(
            f"Created residue record ID {residue.id}: "
            f"composite={composite.id}, B1={metadata['b1']}, "
            f"curves={metadata['curve_count']}, param={metadata['parametrization']}"
        )

        return residue

    def get_available_work(
        self,
        db: Session,
        client_id: str,
        min_target_tlevel: Optional[float] = None,
        max_target_tlevel: Optional[float] = None,
        min_priority: Optional[int] = None,
        min_b1: Optional[int] = None,
        max_b1: Optional[int] = None
    ) -> Optional[ECMResidue]:
        """
        Find an available residue for stage 2 processing.

        Args:
            db: Database session
            client_id: ID of requesting client
            min_target_tlevel: Minimum target t-level
            max_target_tlevel: Maximum target t-level
            min_priority: Minimum composite priority
            min_b1: Minimum B1 bound of residue
            max_b1: Maximum B1 bound of residue

        Returns:
            ECMResidue if found, None otherwise
        """
        # Available residues don't have time-based expiration
        # Only filter by status (and exclude factored composites)
        query = db.query(ECMResidue).join(
            Composite, ECMResidue.composite_id == Composite.id
        ).filter(
            ECMResidue.status == 'available',
            Composite.is_fully_factored == False  # noqa: E712
        )

        # Apply filters
        if min_target_tlevel is not None:
            query = query.filter(Composite.target_t_level >= min_target_tlevel)
        if max_target_tlevel is not None:
            query = query.filter(Composite.target_t_level <= max_target_tlevel)
        if min_priority is not None:
            query = query.filter(Composite.priority >= min_priority)
        if min_b1 is not None:
            query = query.filter(ECMResidue.b1 >= min_b1)
        if max_b1 is not None:
            query = query.filter(ECMResidue.b1 <= max_b1)

        # Prioritize by composite priority (descending), then by creation time (oldest first)
        query = query.order_by(
            Composite.priority.desc(),
            ECMResidue.created_at.asc()
        )

        residue = query.first()
        if residue:
            logger.info(f"Found available residue ID {residue.id} for client {client_id}")
        else:
            logger.info(f"No available residues for client {client_id}")

        return residue

    def claim_residue(
        self,
        db: Session,
        residue_id: int,
        client_id: str,
        claim_timeout_hours: int = 72  # 3 days default for large stage 2 work
    ) -> ECMResidue:
        """
        Claim a residue for stage 2 processing.

        Args:
            db: Database session
            residue_id: ID of residue to claim
            client_id: ID of claiming client
            claim_timeout_hours: Hours until claim expires (default 72h/3 days)

        Returns:
            Updated ECMResidue record

        Raises:
            ValueError: If residue not found or not available
        """
        residue = db.query(ECMResidue).filter(ECMResidue.id == residue_id).first()

        if not residue:
            raise ValueError(f"Residue {residue_id} not found")

        if residue.status != 'available':
            raise ValueError(f"Residue {residue_id} is not available (status: {residue.status})")

        residue.status = 'claimed'
        residue.claimed_at = datetime.utcnow()
        residue.claimed_by = client_id
        # Update expiration to claim timeout
        residue.expires_at = datetime.utcnow() + timedelta(hours=claim_timeout_hours)

        logger.info(f"Residue {residue_id} claimed by {client_id}")
        return residue

    def release_claim(self, db: Session, residue_id: int, client_id: str) -> ECMResidue:
        """
        Release a claimed residue back to available pool.

        Args:
            db: Database session
            residue_id: ID of residue to release
            client_id: ID of client releasing (must match claimer)

        Returns:
            Updated ECMResidue record

        Raises:
            ValueError: If residue not found, not claimed, or wrong client
        """
        residue = db.query(ECMResidue).filter(ECMResidue.id == residue_id).first()

        if not residue:
            raise ValueError(f"Residue {residue_id} not found")

        if residue.status != 'claimed':
            raise ValueError(f"Residue {residue_id} is not claimed (status: {residue.status})")

        if residue.claimed_by != client_id:
            raise ValueError(f"Residue {residue_id} is claimed by {residue.claimed_by}, not {client_id}")

        residue.status = 'available'
        residue.claimed_at = None
        residue.claimed_by = None
        # Clear expiration - available residues don't expire by time
        residue.expires_at = None

        logger.info(f"Residue {residue_id} released by {client_id}")
        return residue

    def complete_residue(
        self,
        db: Session,
        residue_id: int,
        stage2_attempt_id: int
    ) -> Tuple[ECMResidue, Optional[float]]:
        """
        Mark residue as completed after stage 2 finishes.

        This supersedes the stage 1 attempt and deletes the residue file.

        Args:
            db: Database session
            residue_id: ID of the completed residue
            stage2_attempt_id: ID of the stage 2 ECM attempt

        Returns:
            Tuple of (residue, new_t_level)
            - new_t_level: Updated t-level after supersession (if applicable)

        Raises:
            ValueError: If residue or attempt not found
        """
        residue = db.query(ECMResidue).filter(ECMResidue.id == residue_id).first()
        if not residue:
            raise ValueError(f"Residue {residue_id} not found")

        # Get the stage 2 attempt
        stage2_attempt = db.query(ECMAttempt).filter(ECMAttempt.id == stage2_attempt_id).first()
        if not stage2_attempt:
            raise ValueError(f"Stage 2 attempt {stage2_attempt_id} not found")

        # Validate that this is a legitimate stage 2 completion:
        # Must either find a factor OR complete at least 75% of the assigned curves
        has_factor = stage2_attempt.factor_found is not None
        min_curves_required = int(0.75 * residue.curve_count)
        curves_completed = stage2_attempt.curves_completed

        if not has_factor and curves_completed < min_curves_required:
            # Reject this completion and release the residue back to available
            residue.status = 'available'
            residue.claimed_at = None
            residue.claimed_by = None
            residue.expires_at = None
            db.flush()

            logger.warning(
                f"Rejected residue {residue_id} completion: stage2_attempt {stage2_attempt_id} "
                f"has no factor and curves_completed={curves_completed} < {min_curves_required} "
                f"(75% of {residue.curve_count}). Residue released back to pool."
            )
            raise ValueError(
                f"Invalid stage 2 completion: no factor found and only {curves_completed} curves "
                f"completed out of {residue.curve_count} assigned (minimum required: {min_curves_required}, 75%). "
                f"Residue {residue_id} has been released back to the available pool."
            )

        # Validate B2 is sufficient: NULL/-1 (GMP-ECM default) is accepted, but an
        # explicit B2 must be at least 100*B1 to be worth consuming the residue file
        stage2_b2 = stage2_attempt.b2
        if not has_factor and stage2_b2 is not None and stage2_b2 != -1:
            min_b2 = residue.b1 * 100
            if stage2_b2 < min_b2:
                residue.status = 'available'
                residue.claimed_at = None
                residue.claimed_by = None
                residue.expires_at = None
                db.flush()

                logger.warning(
                    f"Rejected residue {residue_id} completion: stage2_attempt {stage2_attempt_id} "
                    f"used B2={stage2_b2} < minimum {min_b2} (100 * B1={residue.b1}). "
                    f"Residue released back to pool."
                )
                raise ValueError(
                    f"Invalid stage 2 completion: B2={stage2_b2} is less than the minimum "
                    f"required {min_b2} (100 * B1={residue.b1}). "
                    f"Residue {residue_id} has been released back to the available pool."
                )

        # Mark stage 1 attempt as superseded (if linked)
        if residue.stage1_attempt_id:
            stage1_attempt = db.query(ECMAttempt).filter(
                ECMAttempt.id == residue.stage1_attempt_id
            ).first()
            if stage1_attempt:
                stage1_attempt.superseded_by = stage2_attempt_id
                db.flush()  # Ensure supersession is visible to subsequent queries
                logger.info(
                    f"Marked stage 1 attempt {residue.stage1_attempt_id} as superseded by {stage2_attempt_id}"
                )

        # Update residue status
        residue.status = 'completed'
        residue.completed_at = datetime.utcnow()
        residue.expires_at = None

        # Delete the residue file
        try:
            file_path = Path(residue.storage_path)
            if file_path.exists():
                file_path.unlink()
                logger.info(f"Deleted residue file: {file_path}")
            else:
                logger.warning(f"Residue file not found for deletion: {file_path}")
        except Exception as e:
            logger.error(f"Error deleting residue file {residue.storage_path}: {e}")

        # Mark orphaned attempts from the same residue as superseded
        # These are partial attempts that were submitted but failed to complete the residue
        # (e.g., client interrupted, then another client completed the same residue)
        orphaned_attempts = db.query(ECMAttempt).filter(
            ECMAttempt.residue_checksum == residue.checksum,
            ECMAttempt.id != stage2_attempt_id,
            ECMAttempt.superseded_by.is_(None)  # Not already superseded
        ).all()

        for orphan in orphaned_attempts:
            orphan.superseded_by = stage2_attempt_id
            logger.info(
                f"Marked orphaned attempt {orphan.id} as superseded by {stage2_attempt_id} "
                f"(same residue checksum {residue.checksum[:16]}...)"
            )

        if orphaned_attempts:
            db.flush()  # Ensure supersession is visible to t-level calculation

        # Recalculate t-level for composite (excluding superseded attempts)
        new_t_level = self._recalculate_composite_t_level(db, residue.composite_id)

        logger.info(
            f"Completed residue {residue_id}: stage2_attempt={stage2_attempt_id}, "
            f"new_t_level={new_t_level}"
        )

        return residue, new_t_level

    def _recalculate_composite_t_level(self, db: Session, composite_id: int) -> Optional[float]:
        """
        Recalculate t-level for a composite, excluding superseded attempts.

        Args:
            db: Database session
            composite_id: ID of composite to recalculate

        Returns:
            New t-level value, or None if calculation fails
        """
        composite = db.query(Composite).filter(Composite.id == composite_id).first()
        if not composite:
            return None

        # Use the t-level calculator's recalculate method which already
        # excludes superseded attempts
        old_t_level = composite.current_t_level or 0.0
        new_t_level = self.t_level_calculator.recalculate_composite_t_level(db, composite)

        logger.info(
            f"Recalculated t-level for composite {composite_id}: "
            f"{old_t_level:.2f} -> {new_t_level:.2f}"
        )

        return new_t_level

    def get_residue_file_path(self, db: Session, residue_id: int) -> Optional[Path]:
        """
        Get the filesystem path for a residue file.

        Args:
            db: Database session
            residue_id: ID of residue

        Returns:
            Path to file, or None if not found
        """
        residue = db.query(ECMResidue).filter(ECMResidue.id == residue_id).first()
        if not residue:
            return None

        file_path = Path(residue.storage_path)
        if file_path.exists():
            return file_path

        logger.warning(f"Residue file not found: {file_path}")
        return None

    def suggest_b2_for_residue(self, db: Session, residue_id: int) -> Optional[int]:
        """
        Suggest an appropriate B2 value for stage 2 based on B1.

        Args:
            db: Database session
            residue_id: ID of residue

        Returns:
            Suggested B2 value, or None if residue not found
        """
        residue = db.query(ECMResidue).filter(ECMResidue.id == residue_id).first()
        if not residue:
            return None

        # Standard B2 = 100 * B1 is a common heuristic
        # For GPU work, even larger ratios can be beneficial
        suggested_b2 = residue.b1 * 100

        # Cap at a reasonable maximum (e.g., 10 trillion)
        max_b2 = 10_000_000_000_000
        suggested_b2 = min(suggested_b2, max_b2)

        return suggested_b2

    def cleanup_expired_claims(self, db: Session) -> int:
        """
        Release claims that have timed out (claimed but not completed in time).

        Only claimed residues have expiration times. Available residues don't expire.
        This releases the claim so another worker can pick up the work.

        Args:
            db: Database session

        Returns:
            Number of claims released
        """
        expired_claims = db.query(ECMResidue).filter(
            ECMResidue.status == 'claimed',
            ECMResidue.expires_at < datetime.utcnow()
        ).all()

        count = 0
        for residue in expired_claims:
            try:
                # Release the claim back to available (don't delete file)
                old_claimer = residue.claimed_by
                residue.status = 'available'
                residue.claimed_at = None
                residue.claimed_by = None
                residue.expires_at = None
                count += 1
                logger.info(f"Released expired claim on residue {residue.id} (was claimed by {old_claimer})")
            except Exception as e:
                logger.error(f"Error releasing claim on residue {residue.id}: {e}")

        if count > 0:
            logger.info(f"Released {count} expired claims")

        return count

    def cleanup_factored_composites(self, db: Session) -> int:
        """
        Clean up residues for composites that have been fully factored.

        Residues are no longer useful once their composite is factored.

        Args:
            db: Database session

        Returns:
            Number of residues cleaned up
        """
        # Find residues for fully factored composites
        residues_to_cleanup = db.query(ECMResidue).join(
            Composite, ECMResidue.composite_id == Composite.id
        ).filter(
            Composite.is_fully_factored == True,  # noqa: E712
            ECMResidue.status.in_(['available', 'claimed'])
        ).all()

        count = 0
        for residue in residues_to_cleanup:
            try:
                file_path = Path(residue.storage_path)
                if file_path.exists():
                    file_path.unlink()
                    logger.info(f"Deleted residue file for factored composite: {file_path}")

                residue.status = 'expired'  # Mark as cleaned up
                count += 1
            except Exception as e:
                logger.error(f"Error cleaning up residue {residue.id}: {e}")

        if count > 0:
            logger.info(f"Cleaned up {count} residues for factored composites")

        return count

    def get_stats(self, db: Session) -> Dict[str, int]:
        """
        Get statistics about residues in the system.

        Args:
            db: Database session

        Returns:
            Dict with counts by status and total pending curves
        """
        stats = {
            'total_available': 0,
            'total_claimed': 0,
            'total_completed': 0,
            'total_expired': 0,
            'total_curves_pending': 0
        }

        # Count by status
        status_counts = db.query(
            ECMResidue.status,
            func.count(ECMResidue.id)
        ).group_by(ECMResidue.status).all()

        for status, count in status_counts:
            if status == 'available':
                stats['total_available'] = count
            elif status == 'claimed':
                stats['total_claimed'] = count
            elif status == 'completed':
                stats['total_completed'] = count
            elif status == 'expired':
                stats['total_expired'] = count

        # Sum curves in available residues
        curves_sum = db.query(func.sum(ECMResidue.curve_count)).filter(
            ECMResidue.status == 'available'
        ).scalar()
        stats['total_curves_pending'] = curves_sum or 0

        return stats
